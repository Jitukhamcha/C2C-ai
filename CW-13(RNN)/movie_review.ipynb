{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfaab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# https://drive.google.com/file/d/192jeGRTCZZfet8ufHPfaMn05T7Biklfw/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a1a3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "\n",
    "# Assumes you're in the root level of the dataset directory.\n",
    "# If you aren't, you'll need to change the relative paths here.\n",
    "train_data = text_dataset_from_directory(\"movie-reviews-dataset/test\")\n",
    "test_data = text_dataset_from_directory(\"movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d2e2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.strings import regex_replace\n",
    "\n",
    "def prepareData(dir):\n",
    "  data = text_dataset_from_directory(dir)\n",
    "  #for filtering\n",
    "  return data.map(\n",
    "    lambda text, label: (regex_replace(text, '<br />', ' '), label),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d21a78c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = prepareData(\"movie-reviews-dataset/test\")\n",
    "test_data = prepareData(\"movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54add890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hope the summary line won\\'t irritate you that much (it\\'s a little homage to the Chappelle Show/Charlie Murphy, but also to the character Daywalker). But I\\'ll try to put all the things I liked about the movie in one paragraph and everything I didn\\'t like in another paragraph, so it will be easier to read!   Let\\'s start with the good things! The quote \"strong bloody violence\" (which is used by rating boards, to describe the content of a movie, does fit here very well. This is not a movie for kids! Or for the faint of hearted! It has Blade as a central character (Wesley Snipes is phenomenal) and a crazy enough story thread to hold/justify the action scenes! The original idea is also very engaging and intelligent. The action scenes are great here too.  OK over to the things I didn\\'t like. The overall story is too thin. It\\'s enough as I\\'ve written above to hold the action scenes together, but there could be more. And a character like Blade deserves more (imo). The drama therefor isn\\'t the best ... also it\\'s use of clich\\xc3\\xa9s doesn\\'t help. Some characters are underwritten ... That\\'s that! :o)'\n",
      "\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_data.take(1):\n",
    "    print(text_batch.numpy()[0])\n",
    "    print(\"\\n\")\n",
    "    print(label_batch.numpy()[0]) # 0 = negative, 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bedf71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ead117d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_tokens = 1000\n",
    "max_len = 100\n",
    "vectorize_layer = TextVectorization(\n",
    "  # Max vocab size. Any words outside of the max_tokens most common ones\n",
    "  # will be treated the same way: as \"out of vocabulary\" (OOV) tokens.\n",
    "  max_tokens=max_tokens,\n",
    "  # Output integer indices, one per string token\n",
    "  output_mode=\"int\",\n",
    "  # Always pad or truncate to exactly this many tokens\n",
    "  output_sequence_length=max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d78d5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
    "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
    "train_texts = train_data.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "532ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "061ffe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "model.add(Embedding(max_tokens + 1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5420e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "model.add(LSTM(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd3c63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          128128    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 64, 128)           128128    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359,297\n",
      "Trainable params: 359,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(max_tokens + 1, 128))\n",
    "\n",
    "# ----- 4. RECURRENT LAYER\n",
    "model.add(LSTM(64))\n",
    "\n",
    "# ----- 5. DENSE HIDDEN LAYER\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "# ----- 6. OUTPUT\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bd64ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9335f539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "782/782 [==============================] - 51s 55ms/step - loss: 0.6934 - accuracy: 0.5005\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 44s 57ms/step - loss: 0.6932 - accuracy: 0.4992\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.6932 - accuracy: 0.4946\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.6933 - accuracy: 0.5001\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 45s 57ms/step - loss: 0.6932 - accuracy: 0.4986\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 43s 55ms/step - loss: 0.6932 - accuracy: 0.4978\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 47s 60ms/step - loss: 0.6932 - accuracy: 0.4958\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.6934 - accuracy: 0.4999\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 44s 56ms/step - loss: 0.6932 - accuracy: 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b166b6670>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM\n",
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "007c5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe6f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model_LSTM = keras.models.load_model('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99ea2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "[[0.50081134]]\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "[[0.50081134]]\n"
     ]
    }
   ],
   "source": [
    "# Should print a very high score like 0.98.\n",
    "print(model_LSTM.predict([\n",
    "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
    "]))\n",
    "\n",
    "# Should print a very low score like 0.01.\n",
    "print(model_LSTM.predict([\n",
    "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8283dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 100)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 100, 128)          128128    \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 20)                2580      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                1344      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 230,805\n",
      "Trainable params: 230,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "# # build model\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(SimpleRNN(128, return_sequences=False))\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9be2d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "663cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ab9e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c760c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 59s 72ms/step - loss: 0.6933 - accuracy: 0.4935\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 54s 69ms/step - loss: 0.6932 - accuracy: 0.4954\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 54s 70ms/step - loss: 0.6932 - accuracy: 0.4954\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.6932 - accuracy: 0.4949\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.6932 - accuracy: 0.4958\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.6932 - accuracy: 0.4935\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 56s 72ms/step - loss: 0.6932 - accuracy: 0.4941\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 55s 70ms/step - loss: 0.6932 - accuracy: 0.4937\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.6932 - accuracy: 0.4953\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 56s 72ms/step - loss: 0.6932 - accuracy: 0.4953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b37158610>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple RNN\n",
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "698ae97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SimpleRNN\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SimpleRNN\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d4b9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7798b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 464ms/step\n",
      "[[0.50095457]]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "[[0.50095457]]\n"
     ]
    }
   ],
   "source": [
    "# Should print a very high score like 0.98.\n",
    "print(model.predict([\n",
    "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
    "]))\n",
    "\n",
    "# Should print a very low score like 0.01.\n",
    "print(model.predict([\n",
    "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7a673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c50a568c9bb54733425ee4b50464281b54488c5e15ff27e4e32e073d46803f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
