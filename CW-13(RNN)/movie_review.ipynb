{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfaab626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "# https://drive.google.com/file/d/192jeGRTCZZfet8ufHPfaMn05T7Biklfw/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1a3e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ghost\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "\n",
    "# Assumes you're in the root level of the dataset directory.\n",
    "# If you aren't, you'll need to change the relative paths here.\n",
    "train_data = text_dataset_from_directory(\"movie-reviews-dataset/test\")\n",
    "test_data = text_dataset_from_directory(\"movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2e2dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.strings import regex_replace\n",
    "\n",
    "def prepareData(dir):\n",
    "  data = text_dataset_from_directory(dir)\n",
    "  #for filtering\n",
    "  return data.map(\n",
    "    lambda text, label: (regex_replace(text, '<br />', ' '), label),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21a78c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = prepareData(\"movie-reviews-dataset/test\")\n",
    "test_data = prepareData(\"movie-reviews-dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54add890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Sherlock Holmes and the Secret Weapon starts in Switzerland as the world's foremost detective Sherlock Holmes (Basil Rathbone) outwits the Nazi's & manages to smuggle a brilliant scientist named Dr. Franz Tobel (William Post Jr.) out of the country & to the relative safety of London. But is London as safe as Holmes thinks? Dr. Tobel has engineered a revolutionary new bomb sight that will change aerial bombardment forever & he has agreed to give it to the British government, but those Nazi's want it just as badly & Holmes arch enemy Professor Moriarty (Lionel Atwill) plans on stealing the secret of the bomb sight & selling it to the Nazi's. Add the bumbling Inspector Lestrade (Denis Hoey) of Scotland Yard, Dr. Tobel's love interest Charlotte Eberli (Kaaren Verne), assassins, mysterious scientists & a puzzling coded message & Holmes has his work cut out to keep Dr. Tobel alive so he can deliver his bomb sight...  Directed by Roy William Neill Sherlock Holmes and the Secret Weapon was the fourth in a series of fourteen Holmes films made between 1939 & 1946 to feature Rathbone & Bruce as Holmes & Watson. The script by Edward T. Lowe Jr., Scott Darling & Edmund L. Hartmann is based on the short 'The Dancing Men' by Sir Arthur Conan Doyle & isn't the tradition Holmes murder mystery as it's more of a wartime adventure story. To neglect what Holmes is all about, the solving of complex crimes & mysteries is a big mistake as far as I'm concerned & the involvement of the Nazi's & the war as a backdrop to the story feels out of place, awkward & just didn't sit too well with me. The dialogue isn't great, Professor Moriarty feels almost like an afterthought as if they couldn't come up with a villain for it & as a whole it's far less engaging than other's in the series. However, at least it's short.  Director Neill does his usual efficient job but you have to cut it a little slack & bear in mind that it was made over 60 years ago. It has no real style or imagination & lacks both atmosphere & intrigue as well.  Technically the film is OK if unspectacular, the black and white cinematography is fine although I understand that a computer colourised version is also available. The acting is alright, Bruce & Hoey do their usual comic relief turns & Rathbone's hairstyle in this looks ridiculous & I'm glad he changed it for later instalments.  Sherlock Holmes and the Secret Weapon was a disappointment when compared to some of the other excellent entries in the series, there is very little by which I can recommend it & everything that made the other's so good seems to be missing here. Leave this one till last & watch some of the better ones first, for die hard fans only.\"\n",
      "\n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_data.take(1):\n",
    "    print(text_batch.numpy()[0])\n",
    "    print(\"\\n\")\n",
    "    print(label_batch.numpy()[0]) # 0 = negative, 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bedf71db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ead117d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_tokens = 1000\n",
    "max_len = 100\n",
    "vectorize_layer = TextVectorization(\n",
    "  # Max vocab size. Any words outside of the max_tokens most common ones\n",
    "  # will be treated the same way: as \"out of vocabulary\" (OOV) tokens.\n",
    "  max_tokens=max_tokens,\n",
    "  # Output integer indices, one per string token\n",
    "  output_mode=\"int\",\n",
    "  # Always pad or truncate to exactly this many tokens\n",
    "  output_sequence_length=max_len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d78d5bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
    "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
    "train_texts = train_data.map(lambda text, label: text)\n",
    "vectorize_layer.adapt(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "532ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "061ffe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "model.add(Embedding(max_tokens + 1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d152d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3c63f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          128128    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                49408     \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 64, 128)           128128    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 64, 128)           128128    \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 1, 128)            128128    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " embedding_4 (Embedding)     (None, 1, 128)            128128    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 921,155\n",
      "Trainable params: 921,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(max_tokens + 1, 128))\n",
    "\n",
    "# ----- 4. RECURRENT LAYER\n",
    "model.add(LSTM(64,dropout=0.2,recurrent_dropout=0.2))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----- 5. DENSE HIDDEN LAYER\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "\n",
    "\n",
    "# ----- 6. OUTPUT\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bd64ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9335f539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'embedding_1/embeddings:0', 'lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'embedding_2/embeddings:0', 'lstm_3/lstm_cell_3/kernel:0', 'lstm_3/lstm_cell_3/recurrent_kernel:0', 'lstm_3/lstm_cell_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'embedding_3/embeddings:0', 'lstm_4/lstm_cell_4/kernel:0', 'lstm_4/lstm_cell_4/recurrent_kernel:0', 'lstm_4/lstm_cell_4/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['embedding/embeddings:0', 'lstm/lstm_cell/kernel:0', 'lstm/lstm_cell/recurrent_kernel:0', 'lstm/lstm_cell/bias:0', 'embedding_1/embeddings:0', 'lstm_1/lstm_cell_1/kernel:0', 'lstm_1/lstm_cell_1/recurrent_kernel:0', 'lstm_1/lstm_cell_1/bias:0', 'embedding_2/embeddings:0', 'lstm_3/lstm_cell_3/kernel:0', 'lstm_3/lstm_cell_3/recurrent_kernel:0', 'lstm_3/lstm_cell_3/bias:0', 'dense/kernel:0', 'dense/bias:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'embedding_3/embeddings:0', 'lstm_4/lstm_cell_4/kernel:0', 'lstm_4/lstm_cell_4/recurrent_kernel:0', 'lstm_4/lstm_cell_4/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0', 'dense_4/kernel:0', 'dense_4/bias:0', 'dense_5/kernel:0', 'dense_5/bias:0', 'dense_6/kernel:0', 'dense_6/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "782/782 [==============================] - 42s 45ms/step - loss: 0.6933 - accuracy: 0.4971\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 36s 46ms/step - loss: 0.6933 - accuracy: 0.4974\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 37s 47ms/step - loss: 0.6932 - accuracy: 0.4974\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 39s 49ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.6932 - accuracy: 0.4984\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 40s 52ms/step - loss: 0.6932 - accuracy: 0.4968\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 42s 53ms/step - loss: 0.6932 - accuracy: 0.4934\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 37s 47ms/step - loss: 0.6932 - accuracy: 0.4985\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 38s 49ms/step - loss: 0.6932 - accuracy: 0.4972\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 40s 51ms/step - loss: 0.6932 - accuracy: 0.4957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0a573afd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LSTM\n",
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "007c5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: LSTM\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe6f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model_LSTM = keras.models.load_model('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99ea2751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[[0.5002929]]\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "[[0.5002929]]\n"
     ]
    }
   ],
   "source": [
    "# Should print a very high score like 0.98.\n",
    "print(model_LSTM.predict([\n",
    "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
    "]))\n",
    "\n",
    "# Should print a very low score like 0.01.\n",
    "print(model_LSTM.predict([\n",
    "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8283dcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          128128    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                2580      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                1344      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 230,805\n",
      "Trainable params: 230,805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "# # build model\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(SimpleRNN(128, return_sequences=True))\n",
    "model.add(SimpleRNN(128, return_sequences=False))\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be2d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663cb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab9e744",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss='binary_crossentropy',\n",
    "  metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c760c269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 63s 76ms/step - loss: 0.6932 - accuracy: 0.4954\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 60s 77ms/step - loss: 0.6932 - accuracy: 0.4967\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.6932 - accuracy: 0.4930\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.6932 - accuracy: 0.4966\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.6932 - accuracy: 0.4920\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.6932 - accuracy: 0.4926\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 58s 74ms/step - loss: 0.6932 - accuracy: 0.4945\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 56s 71ms/step - loss: 0.6932 - accuracy: 0.4911\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 56s 72ms/step - loss: 0.6932 - accuracy: 0.4938\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.6932 - accuracy: 0.4916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2423efd7f70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple RNN\n",
    "model.fit(train_data, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "698ae97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SimpleRNN\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4b9afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model('SimpleRNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7798b38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 469ms/step\n",
      "[[0.5018365]]\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.5018365]]\n"
     ]
    }
   ],
   "source": [
    "# Should print a very high score like 0.98.\n",
    "print(model.predict([\n",
    "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
    "]))\n",
    "\n",
    "# Should print a very low score like 0.01.\n",
    "print(model.predict([\n",
    "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7a673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c50a568c9bb54733425ee4b50464281b54488c5e15ff27e4e32e073d46803f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
